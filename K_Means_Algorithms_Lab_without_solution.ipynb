{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKZjgJnYotecuYoIUmC2oC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahEldreny/Machine-Learning-Unsupervised-Labs-/blob/main/K_Means_Algorithms_Lab_without_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-**means**\n",
        "\n",
        "K-means is an unsupervised learning method for clustering data points. The algorithm iteratively divides data points into K clusters by minimizing the variance in each cluster.\n",
        "\n",
        "Here, we will show you how to estimate the best value for K using the elbow method, then use K-means clustering to group the data points into clusters.\n",
        "# **How does it work**?\n",
        "\n",
        "First, each data point is randomly assigned to one of the K clusters. Then, we compute the centroid (functionally the center) of each cluster, and reassign each data point to the cluster with the closest centroid. We repeat this process until the cluster assignments for each data point are no longer changing.\n",
        "\n",
        "K-means clustering requires us to select K, the number of clusters we want to group the data into. The elbow method lets us graph the inertia (a distance-based metric) and visualize the point at which it starts decreasing linearly. This point is referred to as the \"eblow\" and is a good estimate for the best value for K based on our data.\n",
        "\n",
        "\n",
        "## Example\n",
        "\n",
        "Start by visualizing some data points:"
      ],
      "metadata": {
        "id": "JBgkMf9O3bJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]\n",
        "y = [21,19, 24,17, 16, 25, 24, 22, 21, 21]\n",
        "\n",
        "plt.scatter(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UsqO8JrU3nrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we utilize the elbow method to visualize the intertia for different values of K:"
      ],
      "metadata": {
        "id": "orlMI0hs4FuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Turn the data into a set of points:\n",
        "data = list(zip(x, y))\n",
        "#data = [(4,21), (5,19),(10,24),(4,17),(3,16),(11,25),(14,24),(6,22),(10,21),(12,21)]\n",
        "\n",
        "# In order to find the best value for K, we need to run K-means across our data for a range of possible values.\n",
        "# We only have 10 data points, so the maximum number of clusters is 10.\n",
        "# So for each value K in range(1,11), we train a K-means model and plot the intertia at that number of clusters:\n",
        "inertias = []\n",
        "\n",
        "for i in range(1,11):\n",
        "  kmeans =\n",
        "\n",
        "plt.plot(range(1,11), inertias, marker='o')\n",
        "plt.title('Elbow method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v6hE3IjV4Bd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The elbow method shows that 2 is a good value for K, so we retrain and visualize the result:"
      ],
      "metadata": {
        "id": "BOT9-zdH4XKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans =\n",
        "\n",
        "plt.scatter(x, y, c=kmeans.labels_)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pcLA-OWa4Llh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score"
      ],
      "metadata": {
        "id": "l8sJVR4YGaaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n",
        "silhouette_avg = []\n",
        "for num_clusters in range_n_clusters:\n",
        "\n",
        "  # initialise kmeans\n",
        "  kmeans =\n",
        "\n",
        "\n",
        " # silhouette score\n",
        "  silhouette_avg.append(silhouette_score(data, cluster_labels))\n",
        "plt.plot(range_n_clusters,silhouette_avg,'bx-')\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L5MYCmitFuLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}